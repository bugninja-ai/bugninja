# Bugninja Sensitive Configuration Example
# Copy this file to .env and fill in your secret values
# 
# IMPORTANT: This file contains ONLY sensitive data (API keys, passwords, tokens)
# All other configuration is now stored in bugninja.toml

# =============================================================================
# LLM Configuration (Sensitive Data Only)
# =============================================================================

# LLM Provider Selection (set this to choose your provider)
# Options: azure_openai, openai, anthropic, google_gemini, deepseek, ollama
LLM_PROVIDER=azure_openai

# LLM Model and Settings (optional, can be set in bugninja.toml)
# LLM_MODEL=gpt-4.1
# LLM_TEMPERATURE=0.001

# Azure OpenAI Configuration (required if LLM_PROVIDER=azure_openai)
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_KEY=your-api-key-here

# OpenAI Configuration (required if LLM_PROVIDER=openai)
# OPENAI_API_KEY=your-openai-api-key-here
# OPENAI_BASE_URL=https://api.openai.com/v1

# Anthropic Configuration (required if LLM_PROVIDER=anthropic)
# ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Google Gemini Configuration (required if LLM_PROVIDER=google_gemini)
# GOOGLE_API_KEY=your-google-api-key-here

# DeepSeek Configuration (required if LLM_PROVIDER=deepseek)
# DEEPSEEK_API_KEY=your-deepseek-api-key-here

# Ollama Configuration (optional, defaults to localhost:11434)
# OLLAMA_BASE_URL=http://localhost:11434

# =============================================================================
# Note: All other configuration (logging, paths, browser settings, etc.)
# is now managed in bugninja.toml file for better organization and version control.
# ============================================================================= 